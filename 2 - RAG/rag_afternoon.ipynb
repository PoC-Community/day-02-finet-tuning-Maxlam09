{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-welcome",
   "metadata": {},
   "source": [
    "Hello **Everyone** !  \n",
    "Welcome to the **second part of Day 2** of our AI pool !  \n",
    "This afternoon, we will explore how to make an AI model smarter by giving it access to external knowledge.  \n",
    "\n",
    "Our goal : build a system that can answer questions about **your own documents** (PDFs, texts, etc.) with accurate information.  \n",
    "Does that sound useful ? Let's dive in !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context-problem",
   "metadata": {},
   "source": [
    "**But wait... why do we need this ?**\n",
    "\n",
    "Remember this morning ? We fine-tuned a model to give us false capitals. The model \"learned\" these false facts.  \n",
    "But there is a problem : **what if the information changes ?** What if we have thousands of documents that update every day ?\n",
    "\n",
    "Fine-tuning every time is expensive and slow. We need a smarter approach : **RAG** (Retrieval Augmented Generation).  \n",
    "\n",
    "Think of it like this :\n",
    "- **Fine-tuning** = Teaching a student new facts by heart (slow, expensive)\n",
    "- **RAG** = Giving the student access to a library and teaching them how to search (fast, flexible)\n",
    "\n",
    "But before building RAG, we need to understand **embeddings** - the magic that makes search work !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-title",
   "metadata": {},
   "source": [
    "# **I/ Understanding Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-intro",
   "metadata": {},
   "source": [
    "### **What is an Embedding ?**\n",
    "\n",
    "An embedding is a way to represent text (or images, audio...) as a **list of numbers** (a vector).  \n",
    "\n",
    "Imagine you want to organize books in a library. Instead of organizing them alphabetically, you organize them by **meaning** :\n",
    "- Books about cooking are close together\n",
    "- Books about space are close together\n",
    "- A book about \"cooking in space\" would be somewhere in between\n",
    "\n",
    "Embeddings do exactly this : texts with similar meanings have similar numbers (vectors that are \"close\" in space).\n",
    "\n",
    "**Example :**\n",
    "- \"I love pizza\" → [0.2, 0.8, 0.1, ...]\n",
    "- \"Pizza is my favorite food\" → [0.21, 0.79, 0.12, ...] (very similar)\n",
    "- \"The weather is nice\" → [0.9, 0.1, 0.7, ...] (very different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-packages",
   "metadata": {},
   "source": [
    "### ***1/ Setup: Install the necessary packages***"
   ]
  },
  {
   "cell_type": "code",
   "id": "install-cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:09.409665709Z",
     "start_time": "2026-02-10T22:45:08.553070126Z"
    }
   },
   "source": [
    "%pip install sentence-transformers chromadb numpy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (5.2.2)\r\n",
      "Requirement already satisfied: chromadb in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (1.5.0)\r\n",
      "Requirement already satisfied: numpy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (5.1.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.4.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.10.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.8.0)\r\n",
      "Requirement already satisfied: scipy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.17.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\r\n",
      "Requirement already satisfied: tqdm in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.3)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.4.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (2.12.5)\r\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.4.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\r\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.24.1)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.22.2)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.51.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.78.0)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.0.0)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.21.1)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (35.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (9.1.4)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (6.0.3)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (3.11.7)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (14.3.2)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (4.26.0)\r\n",
      "Requirement already satisfied: packaging>=24.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (26.0)\r\n",
      "Requirement already satisfied: pyproject_hooks in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: anyio in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2026.1.4)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\r\n",
      "Requirement already satisfied: filelock in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\r\n",
      "Requirement already satisfied: shellingham in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\r\n",
      "Requirement already satisfied: typer-slim in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: requests in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\r\n",
      "Requirement already satisfied: requests-oauthlib in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.6.3)\r\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\r\n",
      "Requirement already satisfied: flatbuffers in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\r\n",
      "Requirement already satisfied: protobuf in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\r\n",
      "Requirement already satisfied: sympy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\r\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\r\n",
      "Requirement already satisfied: setuptools in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (82.0.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\r\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.9.4)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\r\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\r\n",
      "Requirement already satisfied: triton==3.6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers) (1.3.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\r\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\r\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "id": "create-embedding-title",
   "metadata": {},
   "source": [
    "### ***2/ Create your first embedding***\n",
    "\n",
    "We will use a pre-trained model from HuggingFace to create embeddings.  \n",
    "The model `all-MiniLM-L6-v2` is small, fast, and works great for most use cases.\n",
    "\n",
    "**Documentation :** https://www.sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "id": "first-embedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:11.236485506Z",
     "start_time": "2026-02-10T22:45:09.410246797Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# TODO: Load the embedding model 'all-MiniLM-L6-v2'\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "text = \"I love artificial intelligence\"\n",
    "\n",
    "# TODO: Create the embedding\n",
    "embedding = embedding_model.encode(text)\n",
    "\n",
    "print(f\"Embedding created.\")\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1489.91it/s, Materializing param=pooler.dense.weight]                        \n",
      "\u001B[1mMPNetModel LOAD REPORT\u001B[0m from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding created.\n",
      "Embedding dimension: 768\n",
      "First 10 values: [-0.04087291  0.07031951 -0.04249007 -0.01306419 -0.02507559  0.04857958\n",
      " -0.03809898 -0.00214754  0.00031533  0.02278556]\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "id": "similarity-title",
   "metadata": {},
   "source": [
    "### ***3/ Measure similarity between texts***\n",
    "\n",
    "Now comes the magic. We can measure how similar two texts are by comparing their embeddings.  \n",
    "We use **cosine similarity** : a value between -1 and 1, where 1 means \"identical meaning\".\n",
    "\n",
    "**Documentation :** https://www.sbert.net/docs/package_reference/util.html\n",
    "\n",
    "**Your task :** Complete the code to calculate similarity between sentences."
   ]
  },
  {
   "cell_type": "code",
   "id": "similarity-calc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:11.315363892Z",
     "start_time": "2026-02-10T22:45:11.260322082Z"
    }
   },
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "sentences = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is my favorite programming language\",\n",
    "    \"The weather is beautiful today\",\n",
    "    \"I enjoy coding and building software\"\n",
    "]\n",
    "\n",
    "# TODO: Create embeddings for all sentences\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "print(\"Similarity with 'I love programming in Python':\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # TODO: Calculate cosine similarity between first embedding and current one\n",
    "    similarity = util.cos_sim(embeddings[0], embeddings[i]).item()\n",
    "    print(f\"  \\\"{sentence}\\\"\")\n",
    "    print(f\"  → Similarity: {similarity:.4f}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with 'I love programming in Python':\n",
      "\n",
      "  \"I love programming in Python\"\n",
      "  → Similarity: 1.0000\n",
      "\n",
      "  \"Python is my favorite programming language\"\n",
      "  → Similarity: 0.8861\n",
      "\n",
      "  \"The weather is beautiful today\"\n",
      "  → Similarity: 0.0930\n",
      "\n",
      "  \"I enjoy coding and building software\"\n",
      "  → Similarity: 0.6886\n",
      "\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "id": "question-similarity",
   "metadata": {},
   "source": [
    "**Question :** Which sentences have the highest similarity ? Does it make sense to you ?  \n",
    "Take a moment to analyze the results before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-title",
   "metadata": {},
   "source": [
    "### ***4/ Visualize embeddings (bonus)***\n",
    "\n",
    "Embeddings have 384 dimensions - impossible to visualize directly.  \n",
    "We can use **dimensionality reduction** to project them into 2D and see how texts are organized.\n",
    "\n",
    "**Documentation :** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "This is optional but helps understand how embeddings work."
   ]
  },
  {
   "cell_type": "code",
   "id": "visualize-embeddings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:12.144935130Z",
     "start_time": "2026-02-10T22:45:11.315951592Z"
    }
   },
   "source": [
    "%pip install matplotlib scikit-learn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "texts = [\n",
    "    # Tech topic\n",
    "    \"I love programming in Python\",\n",
    "    \"JavaScript is great for web development\",\n",
    "    \"Machine learning is fascinating\",\n",
    "    # Food topic  \n",
    "    \"Pizza is my favorite food\",\n",
    "    \"I love cooking Italian pasta\",\n",
    "    \"Sushi is delicious\",\n",
    "    # Nature topic\n",
    "    \"The mountains are beautiful\",\n",
    "    \"I love hiking in the forest\",\n",
    "    \"The ocean is peaceful\"\n",
    "]\n",
    "\n",
    "# TODO: Create embeddings for all texts\n",
    "#text_embeddings = ...\n",
    "\n",
    "# TODO: Reduce to 2D using PCA\n",
    "#pca = ...\n",
    "#embeddings_2d = ...\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'blue', 'blue', 'red', 'red', 'red', 'green', 'green', 'green']\n",
    "\n",
    "#for i, (x, y) in enumerate(embeddings_2d):\n",
    "#    plt.scatter(x, y, c=colors[i], s=100)\n",
    "#    plt.annotate(texts[i][:30] + \"...\", (x, y), fontsize=8)\n",
    "\n",
    "plt.title(\"Embeddings visualized in 2D (Blue=Tech, Red=Food, Green=Nature)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice how similar topics cluster together.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (3.10.8)\r\n",
      "Requirement already satisfied: scikit-learn in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (1.8.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (4.61.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (2.4.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (26.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (12.1.0)\r\n",
      "Requirement already satisfied: pyparsing>=3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (3.3.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn) (1.17.0)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notice how similar topics cluster together.\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "id": "part2-title",
   "metadata": {},
   "source": [
    "# **II/ Building a Vector Database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vectordb-intro",
   "metadata": {},
   "source": [
    "Now that we understand embeddings, we need a place to **store** them efficiently.  \n",
    "\n",
    "A **vector database** is like a regular database, but optimized for :\n",
    "- Storing embeddings (lists of numbers)\n",
    "- Finding similar vectors very fast (even with millions of entries)\n",
    "\n",
    "We will use **ChromaDB**, which is simple and works great for learning.\n",
    "\n",
    "**Other popular options :** Pinecone, Weaviate, Qdrant, FAISS, Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-db-title",
   "metadata": {},
   "source": [
    "### ***1/ Create a ChromaDB collection***\n",
    "\n",
    "A \"collection\" in ChromaDB is like a table in a regular database.  \n",
    "It stores your documents and their embeddings.\n",
    "\n",
    "**Documentation :** https://docs.trychroma.com/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "id": "create-chromadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:12.180080934Z",
     "start_time": "2026-02-10T22:45:12.167137067Z"
    }
   },
   "source": [
    "import chromadb\n",
    "\n",
    "# TODO: Create a ChromaDB client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# TODO: Create a collection named \"my_knowledge_base\"\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"my_knowledge_base\")\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(name=\"my_knowledge_base\")\n",
    "\n",
    "print(f\"Collection '{collection.name}' created.\")\n",
    "print(f\"Currently contains {collection.count()} documents\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_knowledge_base' created.\n",
      "Currently contains 0 documents\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "id": "add-docs-title",
   "metadata": {},
   "source": [
    "### ***2/ Add documents to the database***\n",
    "\n",
    "Let's add some documents about a fictional company.  \n",
    "Later, we will ask questions and retrieve relevant information.\n",
    "\n",
    "**Your task :** Add documents to the collection using the `add()` method.\n",
    "\n",
    "**Hint :** ChromaDB requires each document to have a **unique string ID**. You can generate them from the index, for example : `[\"doc_0\", \"doc_1\", \"doc_2\", ...]`.  \n",
    "Use a list comprehension like `[f\"doc_{i}\" for i in range(len(documents))]` to create them."
   ]
  },
  {
   "cell_type": "code",
   "id": "add-documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:12.543807392Z",
     "start_time": "2026-02-10T22:45:12.180803890Z"
    }
   },
   "source": [
    "documents = [\n",
    "    \"TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\",\n",
    "    \"TechCorp specializes in artificial intelligence solutions for healthcare.\",\n",
    "    \"The company has 150 employees and offices in San Francisco and London.\",\n",
    "    \"TechCorp's main product is MedAI, a diagnostic assistant for doctors.\",\n",
    "    \"In 2023, TechCorp raised $50 million in Series B funding from Sequoia Capital.\",\n",
    "    \"The CEO of TechCorp is Alice Johnson, who previously worked at Google.\",\n",
    "    \"TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\",\n",
    "    \"The company plans to expand to Asia in 2024, starting with Japan and Singapore.\",\n",
    "    \"MedAI can analyze X-rays, MRIs, and CT scans with 95% accuracy.\",\n",
    "    \"TechCorp won the Best AI Startup award at TechCrunch Disrupt 2023.\"\n",
    "]\n",
    "\n",
    "# TODO: Add documents to the collection with unique IDs\n",
    "collection.add(\n",
    "    ids=[f'doc_{index}' for index, doc in enumerate(documents)],\n",
    "    documents=documents,\n",
    ")\n",
    "\n",
    "print(f\"Added {collection.count()} documents to the collection.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 documents to the collection.\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "id": "query-title",
   "metadata": {},
   "source": [
    "### ***3/ Search for relevant documents***\n",
    "\n",
    "Now the magic happens. We can search for documents by **meaning**, not just keywords.  \n",
    "The database will find documents that are semantically similar to our query.\n",
    "\n",
    "**Your task :** Use the `query()` method to search for relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "query-documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:12.720084156Z",
     "start_time": "2026-02-10T22:45:12.548026397Z"
    }
   },
   "source": [
    "query = \"Who founded the company and when ?\"\n",
    "\n",
    "# TODO: Query the collection and get 3 results\n",
    "results = collection.query(\n",
    "    query_texts=query,\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(\"Most relevant documents:\")\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"  {i+1}. {doc}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"Who founded the company and when ?\"\n",
      "\n",
      "Most relevant documents:\n",
      "  1. TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n",
      "  2. The CEO of TechCorp is Alice Johnson, who previously worked at Google.\n",
      "  3. The company has 150 employees and offices in San Francisco and London.\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "id": "experiment-title",
   "metadata": {},
   "source": [
    "### ***4/ Experiment with different queries***\n",
    "\n",
    "Try different questions and see how the system finds relevant documents.  \n",
    "Notice how it understands meaning, not just exact word matches."
   ]
  },
  {
   "cell_type": "code",
   "id": "experiment-queries",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:13.359655419Z",
     "start_time": "2026-02-10T22:45:12.723870914Z"
    }
   },
   "source": [
    "test_queries = [\n",
    "    \"What does the company sell ?\",\n",
    "    \"How much money did they raise ?\",\n",
    "    \"Where are the offices located ?\",\n",
    "    \"Tell me about the medical AI product\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    # TODO: Query the collection with 2 results\n",
    "    results = collection.query(\n",
    "    query_texts=query,\n",
    "    n_results=2,\n",
    ")\n",
    "    \n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(\"Results:\")\n",
    "    for doc in results['documents'][0]:\n",
    "        print(f\"   → {doc}\")\n",
    "    print(\"-\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: \"What does the company sell ?\"\n",
      "Results:\n",
      "   → The company has 150 employees and offices in San Francisco and London.\n",
      "   → The CEO of TechCorp is Alice Johnson, who previously worked at Google.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"How much money did they raise ?\"\n",
      "Results:\n",
      "   → In 2023, TechCorp raised $50 million in Series B funding from Sequoia Capital.\n",
      "   → TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"Where are the offices located ?\"\n",
      "Results:\n",
      "   → The company has 150 employees and offices in San Francisco and London.\n",
      "   → TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"Tell me about the medical AI product\"\n",
      "Results:\n",
      "   → TechCorp specializes in artificial intelligence solutions for healthcare.\n",
      "   → TechCorp's main product is MedAI, a diagnostic assistant for doctors.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "id": "part3-title",
   "metadata": {},
   "source": [
    "# **III/ Building a RAG System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-intro",
   "metadata": {},
   "source": [
    "Now we combine everything into a complete **RAG** (Retrieval Augmented Generation) system.\n",
    "\n",
    "**How RAG works :**\n",
    "1. User asks a question\n",
    "2. We **search** our vector database for relevant documents (Retrieval)\n",
    "3. We give those documents + the question to an **LLM** (Augmented)\n",
    "4. The LLM generates an answer based on the context (Generation)\n",
    "\n",
    "This is powerful because :\n",
    "- The LLM has access to **your specific data**\n",
    "- Answers are **grounded** in real documents (less hallucination)\n",
    "- You can **update** the knowledge base without retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-llm-title",
   "metadata": {},
   "source": [
    "ic key is:\n",
    "test_queries### ***1/ Setup the LLM***\n",
    "\n",
    "We will use the **Ollama** API to run a local LLM.\n",
    "\n",
    "**First, install Ollama and download the model :**\n",
    "\n",
    "1. Install Ollama from [ollama.com](https://ollama.com/)\n",
    "2. Open a terminal and run :\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "```\n",
    "3. Make sure Ollama is running :\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "**Documentation :** https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion"
   ]
  },
  {
   "cell_type": "code",
   "id": "setup-llm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:14.082433348Z",
     "start_time": "2026-02-10T22:45:13.375273090Z"
    }
   },
   "source": [
    "%pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "LLM_URL = \"http://localhost:11434/api/generate\"\n",
    "LLM_MODEL = \"llama3.2:3b\"\n",
    "\n",
    "print(f\"Using Ollama with model: {LLM_MODEL}\")\n",
    "print(\"Make sure Ollama is running: 'ollama serve'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (2.32.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (2026.1.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using Ollama with model: llama3.2:3b\n",
      "Make sure Ollama is running: 'ollama serve'\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "id": "rag-function-title",
   "metadata": {},
   "source": [
    "### ***2/ Build the RAG pipeline***\n",
    "\n",
    "Let's create a function that :\n",
    "1. Takes a user question\n",
    "2. Retrieves relevant documents from ChromaDB\n",
    "3. Creates a prompt with the context\n",
    "4. Sends it to the LLM and returns the answer\n",
    "\n",
    "**Your task :** Complete the RAG function below.\n",
    "\n",
    "**Hint :** To call Ollama, use the `requests` library :\n",
    "```python\n",
    "response = requests.post(LLM_URL, json={\n",
    "    \"model\": LLM_MODEL,\n",
    "    \"prompt\": your_prompt,\n",
    "    \"stream\": False\n",
    "})\n",
    "```\n",
    "The answer is in `response.json()[\"response\"]`."
   ]
  },
  {
   "cell_type": "code",
   "id": "rag-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:14.114969822Z",
     "start_time": "2026-02-10T22:45:14.102725717Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "def ask_with_rag(question: str, n_results: int = 3) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    RAG pipeline: Retrieve relevant docs and generate an answer.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        n_results: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (answer, source documents)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Retrieve relevant documents from the collection\n",
    "    results = collection.query(\n",
    "        query_texts=question,\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    # TODO: Build the context string from retrieved documents\n",
    "    context = \"\".join([document for document in results['documents'][0]])\n",
    "\n",
    "    # TODO: Create a prompt that includes the context and question\n",
    "    prompt = f\"\"\"Use the following pieces of context to answer the question at the end.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"\"\"\n",
    "\n",
    "    # TODO: Call Ollama API and extract the response\n",
    "    response = requests.post(LLM_URL, json={\n",
    "    \"model\": LLM_MODEL,\n",
    "    \"prompt\": prompt,\n",
    "    \"stream\": False\n",
    "})\n",
    "    answer = response.json()[\"response\"]\n",
    "    \n",
    "    return answer, results['documents'][0]\n",
    "\n",
    "print(\"RAG function created.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG function created.\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "id": "test-rag-title",
   "metadata": {},
   "source": [
    "### ***3/ Test your RAG system***\n",
    "\n",
    "Now let's test our RAG system with various questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "test-rag",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:23.155155396Z",
     "start_time": "2026-02-10T22:45:14.115876606Z"
    }
   },
   "source": [
    "test_questions = [\n",
    "    \"Who is the CEO of TechCorp ?\",\n",
    "    \"What is MedAI and what can it do ?\",\n",
    "    \"How much funding did the company raise ?\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "\n",
    "    try:\n",
    "        answer, sources = ask_with_rag(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"\\nSources used:\")\n",
    "        for source in sources:\n",
    "            print(f\"   - {source}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure Ollama is running or your API key is set.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Question: Who is the CEO of TechCorp ?\n",
      "\n",
      "Answer: The CEO of TechCorp is Alice Johnson.\n",
      "\n",
      "Sources used:\n",
      "   - The CEO of TechCorp is Alice Johnson, who previously worked at Google.\n",
      "   - TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n",
      "   - TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\n",
      "\n",
      "============================================================\n",
      "Question: What is MedAI and what can it do ?\n",
      "\n",
      "Answer: MedAI is a diagnostic assistant designed to help doctors make accurate diagnoses. It can analyze medical imaging files such as X-rays, MRIs, and CT scans with 95% accuracy, making it a valuable tool for healthcare professionals in the field of artificial intelligence solutions.\n",
      "\n",
      "Sources used:\n",
      "   - TechCorp's main product is MedAI, a diagnostic assistant for doctors.\n",
      "   - MedAI can analyze X-rays, MRIs, and CT scans with 95% accuracy.\n",
      "   - TechCorp specializes in artificial intelligence solutions for healthcare.\n",
      "\n",
      "============================================================\n",
      "Question: How much funding did the company raise ?\n",
      "\n",
      "Answer: TechCorp raised $50 million.\n",
      "\n",
      "Sources used:\n",
      "   - In 2023, TechCorp raised $50 million in Series B funding from Sequoia Capital.\n",
      "   - TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\n",
      "   - TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "id": "compare-title",
   "metadata": {},
   "source": [
    "### ***4/ Compare: With RAG vs Without RAG***\n",
    "\n",
    "Let's see the difference between asking the LLM directly vs using RAG.  \n",
    "This shows why RAG is so powerful for domain-specific questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "compare-rag",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:32.841037260Z",
     "start_time": "2026-02-10T22:45:23.171039307Z"
    }
   },
   "source": [
    "def ask_without_rag(question: str) -> str:\n",
    "    \"\"\"Ask the LLM directly without any context.\"\"\"\n",
    "    # TODO: Create a simple prompt and call Ollama\n",
    "    prompt = f\"\"\"Answer the question at the end.\\n\\nQuestion: {question}\\nHelpful Answer:\"\"\"\n",
    "\n",
    "    # TODO: Call Ollama API and extract the response\n",
    "    response = requests.post(LLM_URL, json={\n",
    "        \"model\": LLM_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    answer = response.json()[\"response\"]\n",
    "\n",
    "    return answer, results['documents'][0]\n",
    "\n",
    "question = \"Who is the CEO of TechCorp and what is their background ?\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"\\nWITHOUT RAG (LLM doesn't know about TechCorp):\")\n",
    "    print(ask_without_rag(question))\n",
    "    \n",
    "    print(\"\\nWITH RAG (LLM has access to our documents):\")\n",
    "    answer, _ = ask_with_rag(question)\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the CEO of TechCorp and what is their background ?\n",
      "\n",
      "============================================================\n",
      "\n",
      "WITHOUT RAG (LLM doesn't know about TechCorp):\n",
      "('I don\\'t have information on a specific CEO named in your request for \"TechCorp.\" However, I can provide you with some general information about CEOs in the tech industry:\\n\\nThere are several well-known CEOs in the tech industry, such as:\\n\\n* Sundar Pichai - CEO of Alphabet Inc. (Google\\'s parent company) and formerly CEO of Google.\\n* Tim Cook - CEO of Apple Inc.\\n* Satya Nadella - CEO of Microsoft Corporation.\\n\\nIf you could provide more context or clarify which TechCorp you are referring to, I may be able to help further.\\n\\nNote: TechCorp is not a publicly recognized company, so it\\'s possible that the information provided about their CEO and background may not be accurate or up-to-date.', ['TechCorp specializes in artificial intelligence solutions for healthcare.', \"TechCorp's main product is MedAI, a diagnostic assistant for doctors.\"])\n",
      "\n",
      "WITH RAG (LLM has access to our documents):\n",
      "According to the provided context, the CEO of TechCorp is Alice Johnson. Her background is that she previously worked at Google.\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "id": "part4-title",
   "metadata": {},
   "source": [
    "# **IV/ RAG on Real Documents : Chunking & Multi-File Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunking-intro",
   "metadata": {},
   "source": [
    "### ***1/ Understanding chunking***\n",
    "\n",
    "In Parts II and III, we worked with short, single-sentence documents. That made things easy.  \n",
    "But in real applications, your knowledge base is made of **long documents** : PDFs, reports, articles, internal docs...\n",
    "\n",
    "You can't just embed an entire 10-page document as a single vector. Why ?\n",
    "- Embeddings work best on **short texts** (a few sentences). A single embedding for a whole document would lose the details.\n",
    "- When you retrieve a long document, most of it is **irrelevant** to the question. You'd waste the LLM's context window.\n",
    "- LLMs have **context limits** - you can't feed them an entire book.\n",
    "\n",
    "The solution is **chunking** : splitting long documents into smaller, meaningful pieces.\n",
    "\n",
    "**How chunking works :**\n",
    "- We define a **maximum chunk size** (e.g. 500 characters).\n",
    "- We walk through the text and cut at approximately every 500 characters.\n",
    "- But we don't cut in the middle of a sentence ! We look for the **last sentence boundary** (period, exclamation mark...) before the limit, so each chunk contains **complete sentences**.\n",
    "- We also add an **overlap** between chunks (e.g. 100 characters). This means the end of one chunk is repeated at the start of the next one. This prevents losing context at the boundaries - if an important fact spans two chunks, the overlap ensures it appears fully in at least one of them.\n",
    "\n",
    "**Example with chunk_size=500, overlap=100 :**\n",
    "```\n",
    "Document: \"Sentence A. Sentence B. Sentence C. Sentence D. Sentence E. ...\"\n",
    "\n",
    "Chunk 1: \"Sentence A. Sentence B. Sentence C.\"        (480 chars, cut at last period before 500)\n",
    "Chunk 2: \"Sentence C. Sentence D. Sentence E.\"          (starts 100 chars before the end of chunk 1)\n",
    "```\n",
    "\n",
    "In the `documents/` folder, you will find **5 text files** about TechCorp.  \n",
    "Your task is to implement the chunking function, load the files, chunk them, and build a complete RAG system over real documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "chunking-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:32.871622666Z",
     "start_time": "2026-02-10T22:45:32.855991258Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks, cutting at sentence boundaries.\n",
    "    \n",
    "    Args:\n",
    "        text: The full text to chunk\n",
    "        chunk_size: Maximum size of each chunk (in characters)\n",
    "        overlap: Number of characters to overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        # TODO: Calculate the end position\n",
    "        end = start + chunk_size\n",
    "        \n",
    "        # TODO: Try to end at a sentence boundary (find last period before end)\n",
    "        # Hint: use text.rfind(\".\", start, end) to find the last period in the range\n",
    "        if end < len(text):\n",
    "            end = text.rfind(\".\", start, end)\n",
    "        \n",
    "        # TODO: Extract the chunk (strip whitespace) and append it to the list\n",
    "        # TODO: Update start position (move forward by chunk length minus overlap)\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --- Load all .txt files from the documents/ folder ---\n",
    "documents_dir = \"documents\"\n",
    "all_chunks = []\n",
    "chunk_sources = []\n",
    "\n",
    "for filename in sorted(os.listdir(documents_dir)):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "    \n",
    "    filepath = os.path.join(documents_dir, filename)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # TODO: Chunk the file content\n",
    "    file_chunks = chunk_text(content)\n",
    "    \n",
    "    for chunk in file_chunks:\n",
    "        all_chunks.append(chunk)\n",
    "        chunk_sources.append(filename)\n",
    "    \n",
    "    print(f\"Loaded '{filename}' -> {len(file_chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nTotal: {len(all_chunks)} chunks from {len(set(chunk_sources))} files\")\n",
    "print(f\"\\nExample chunk (chunk #1):\")\n",
    "print(f\"  Source: {chunk_sources[0]}\")\n",
    "print(f\"  Length: {len(all_chunks[0])} chars\")\n",
    "print(f\"  Content: \\\"{all_chunks[0][:150]}...\\\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'company_overview.txt' -> 6 chunks\n",
      "Loaded 'expansion_plans.txt' -> 8 chunks\n",
      "Loaded 'financials.txt' -> 8 chunks\n",
      "Loaded 'partnerships.txt' -> 8 chunks\n",
      "Loaded 'products.txt' -> 9 chunks\n",
      "\n",
      "Total: 39 chunks from 5 files\n",
      "\n",
      "Example chunk (chunk #1):\n",
      "  Source: company_overview.txt\n",
      "  Length: 390 chars\n",
      "  Content: \"TechCorp: Company Overview\n",
      "\n",
      "TechCorp is a leading artificial intelligence company headquartered in San Francisco, California. Founded in 2020 by Alice...\"\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "id": "hu04m2nke1s",
   "metadata": {},
   "source": [
    "### ***2/ Store chunks in a vector database***\n",
    "\n",
    "Now that we have chunks from multiple files, let's store them in a **new ChromaDB collection** and build a full RAG system over real documents.\n",
    "\n",
    "**Your task :** Add all chunks to a new collection, keeping track of which file each chunk came from (using **metadata**)."
   ]
  },
  {
   "cell_type": "code",
   "id": "sje1b7j0hds",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:45:34.028752979Z",
     "start_time": "2026-02-10T22:45:32.872254451Z"
    }
   },
   "source": [
    "# TODO: Create a new ChromaDB collection named \"techcorp_docs\"\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"techcorp_docs\")\n",
    "except:\n",
    "    pass\n",
    "docs_collection = chroma_client.create_collection(name=\"techcorp_docs\")\n",
    "\n",
    "# TODO: Add all chunks to the collection\n",
    "# Each chunk needs: a unique ID, the chunk text as document, and metadata with the source filename\n",
    "# Hint: metadata is a list of dicts, e.g. [{\"source\": \"file1.txt\"}, {\"source\": \"file2.txt\"}, ...]\n",
    "metadatas = [{\"source\": filename} for filename in chunk_sources]\n",
    "docs_collection.add(\n",
    "    ids=[f'chunk_{index}' for index in range(len(all_chunks))],\n",
    "    documents=all_chunks,\n",
    "    metadatas=metadatas,\n",
    ")\n",
    "\n",
    "print(f\"Stored {docs_collection.count()} chunks in the 'techcorp_docs' collection.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 39 chunks in the 'techcorp_docs' collection.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "id": "0nbnuf5f9kg",
   "metadata": {},
   "source": [
    "### ***3/ RAG over real documents***\n",
    "\n",
    "Let's test our complete pipeline : **chunked documents + vector DB + LLM**.  \n",
    "The questions below require information spread across different files. Only a RAG system with proper chunking can answer them accurately."
   ]
  },
  {
   "cell_type": "code",
   "id": "4wy06z9srmu",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:49:10.091346242Z",
     "start_time": "2026-02-10T22:48:23.606562493Z"
    }
   },
   "source": [
    "def ask_docs(question: str, n_results: int = 5) -> tuple[str, list]:\n",
    "    \"\"\"RAG pipeline over the chunked documents collection.\"\"\"\n",
    "    \n",
    "    # TODO: Query the docs_collection for relevant chunks\n",
    "    results = docs_collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    \n",
    "    # TODO: Build context from retrieved chunks\n",
    "    context = \"\".join([document for document in results['documents'][0]])\n",
    "    \n",
    "    # TODO: Create a prompt and call Ollama (same pattern as ask_with_rag)\n",
    "    prompt = prompt = f\"\"\"Use the following pieces of context to answer the question at the end.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"\"\"\n",
    "    \n",
    "    response = requests.post(LLM_URL, json={\n",
    "        \"model\": LLM_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    answer = response.json()[\"response\"]\n",
    "    \n",
    "    return answer, results['documents'][0], results['metadatas'][0]\n",
    "\n",
    "\n",
    "test_questions = [\n",
    "    \"What is TechCorp's revenue growth from 2022 to 2023 ?\",\n",
    "    \"Which hospitals are partners of TechCorp ?\",\n",
    "    \"What is PathAI and when will it launch ?\",\n",
    "    \"How does MedAI integrate into hospital workflows ?\",\n",
    "    \"What is TechCorp's expansion plan for Asia ?\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    try:\n",
    "        answer, sources, metadatas = ask_docs(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"\\nSources:\")\n",
    "        for source, meta in zip(sources, metadatas):\n",
    "            print(f\"   [{meta['source']}] {source[:80]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Question: What is TechCorp's revenue growth from 2022 to 2023 ?\n",
      "\n",
      "Answer: TechCorp's revenue grew by 150% from $10 million in fiscal year 2022 to $25 million in fiscal year 2023.\n",
      "\n",
      "Sources:\n",
      "   [financials.txt] and Growth\n",
      "TechCorp generated its first revenue in mid-2022 when MedAI became co...\n",
      "   [financials.txt] TechCorp: Financial Information and Funding History\n",
      "\n",
      "Seed Round (2020)\n",
      "TechCorp ...\n",
      "   [financials.txt] rial with promising results, and the company had signed letters of intent with f...\n",
      "   [financials.txt] the end of 2025, assuming current growth rates continue and operating expenses a...\n",
      "   [expansion_plans.txt] TechCorp: International Expansion and Future Plans\n",
      "\n",
      "Asia-Pacific Expansion (2024...\n",
      "\n",
      "============================================================\n",
      "Question: Which hospitals are partners of TechCorp ?\n",
      "\n",
      "Answer: The text mentions the following hospitals as partners of TechCorp:\n",
      "\n",
      "1. Stanford Medical Center (in the United States)\n",
      "2. University College London Hospitals (UCLH) (in Europe)\n",
      "\n",
      "Additionally, it is mentioned that TechCorp also has partnerships with three major university hospitals for clinical validation of its AI models, but their names are not specified in the provided context.\n",
      "\n",
      "Note that Charité Hospital in Berlin is also mentioned as a partner in Europe, but it's not clear if it's one of the \"three major university hospitals\" or an additional partnership.\n",
      "\n",
      "Sources:\n",
      "   [partnerships.txt] TechCorp: Partnerships and Collaborations\n",
      "\n",
      "Hospital Partnerships\n",
      "TechCorp has es...\n",
      "   [company_overview.txt] met while working at Google's DeepMind division, where they collaborated on medi...\n",
      "   [company_overview.txt] ient outcomes. Several of TechCorp's current product features originated from th...\n",
      "   [company_overview.txt] TechCorp: Company Overview\n",
      "\n",
      "TechCorp is a leading artificial intelligence compan...\n",
      "   [partnerships.txt] eement for MedAI Pro in October 2023, deploying the system across its entire net...\n",
      "\n",
      "============================================================\n",
      "Question: What is PathAI and when will it launch ?\n",
      "\n",
      "Answer: Based on the provided context, PathAI appears to be a new module developed by TechCorp, specifically focused on digital pathology. Unfortunately, the text does not mention a specific launch date for PathAI. However, it does state that early results from pilot programs have been promising, with a 92% accuracy rate for detecting breast cancer in biopsy samples, and the company expects Japanese regulatory approval by mid-2024.\n",
      "\n",
      "Sources:\n",
      "   [products.txt] time. The enterprise solution also includes a dedicated support team and guarant...\n",
      "   [expansion_plans.txt] and Medical Devices Agency (PMDA) to obtain approval under the accelerated AI me...\n",
      "   [partnerships.txt]  its primary infrastructure provider, leveraging Google's TPU chips for model tr...\n",
      "   [products.txt] chCorp launched MedAI Pro, an enterprise version of the product designed for lar...\n",
      "   [financials.txt] the end of 2025, assuming current growth rates continue and operating expenses a...\n",
      "\n",
      "============================================================\n",
      "Question: How does MedAI integrate into hospital workflows ?\n",
      "\n",
      "Answer: According to the context provided, MedAI integrates directly into hospital PACS (Picture Archiving and Communication System) workflows through standard DICOM protocols. This means that doctors do not need to change their existing workflow to use the tool, as it seamlessly integrates with their current systems.\n",
      "\n",
      "Sources:\n",
      "   [products.txt] chCorp launched MedAI Pro, an enterprise version of the product designed for lar...\n",
      "   [products.txt] cal images, carefully curated in partnership with Stanford Medical Center and Jo...\n",
      "   [partnerships.txt] TechCorp: Partnerships and Collaborations\n",
      "\n",
      "Hospital Partnerships\n",
      "TechCorp has es...\n",
      "   [partnerships.txt] n with Stanford includes a joint research agreement for developing new AI models...\n",
      "   [products.txt] %, which is comparable to the performance of experienced radiologists with over ...\n",
      "\n",
      "============================================================\n",
      "Question: What is TechCorp's expansion plan for Asia ?\n",
      "\n",
      "Answer: According to the context provided, TechCorp's Asia-Pacific expansion plan includes:\n",
      "\n",
      "1. Opening its first Asian office in Tokyo, Japan in Q1 2024.\n",
      "2. Following that with a second office in Singapore in Q3 2024.\n",
      "\n",
      "Additionally, the company has already signed a memorandum of understanding with Singapore's National University Health System (NUHS) for a pilot deployment of MedAI across three hospitals.\n",
      "\n",
      "Sources:\n",
      "   [expansion_plans.txt] TechCorp: International Expansion and Future Plans\n",
      "\n",
      "Asia-Pacific Expansion (2024...\n",
      "   [expansion_plans.txt] ub for Southeast Asia, covering markets including Malaysia, Thailand, Indonesia,...\n",
      "   [financials.txt] TechCorp: Financial Information and Funding History\n",
      "\n",
      "Seed Round (2020)\n",
      "TechCorp ...\n",
      "   [financials.txt] rial with promising results, and the company had signed letters of intent with f...\n",
      "   [expansion_plans.txt] and Medical Devices Agency (PMDA) to obtain approval under the accelerated AI me...\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-title",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-content",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations !** You have completed this afternoon's session on RAG.\n",
    "\n",
    "**What you learned today :**\n",
    "\n",
    "- **Embeddings** : Transform text into vectors that capture meaning  \n",
    "- **Vector Databases** : Store and search embeddings efficiently (ChromaDB)  \n",
    "- **RAG Pipeline** : Retrieve relevant documents + Generate answers with LLM  \n",
    "- **Chunking** : Split large documents for better retrieval  \n",
    "\n",
    "**Key takeaways :**\n",
    "- RAG lets you give LLMs access to **your specific data** without retraining\n",
    "- Embeddings enable **semantic search** (by meaning, not just keywords)\n",
    "\n",
    "**What's next ? Ideas to explore :**\n",
    "- Check out `bonus.ipynb` for an introduction to **GraphRAG**\n",
    "- Build a RAG system with your own documents (PDFs, web pages)\n",
    "- Try different embedding models (Cohere, local models)\n",
    "- Add metadata filtering to your searches\n",
    "- Experiment with reranking strategies\n",
    "\n",
    "---\n",
    "\n",
    "**Combining with this morning :**  \n",
    "This morning you learned **fine-tuning** (adapting model weights).  \n",
    "This afternoon you learned **RAG** (giving the model external knowledge).  \n",
    "\n",
    "In practice, you often use **both** :\n",
    "- Fine-tune for style/format/domain language\n",
    "- RAG for factual, up-to-date information\n",
    "\n",
    "**Great work today !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
