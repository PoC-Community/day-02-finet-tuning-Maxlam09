{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-welcome",
   "metadata": {},
   "source": [
    "Hello **Everyone** !  \n",
    "Welcome to the **second part of Day 2** of our AI pool !  \n",
    "This afternoon, we will explore how to make an AI model smarter by giving it access to external knowledge.  \n",
    "\n",
    "Our goal : build a system that can answer questions about **your own documents** (PDFs, texts, etc.) with accurate information.  \n",
    "Does that sound useful ? Let's dive in !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context-problem",
   "metadata": {},
   "source": [
    "**But wait... why do we need this ?**\n",
    "\n",
    "Remember this morning ? We fine-tuned a model to give us false capitals. The model \"learned\" these false facts.  \n",
    "But there is a problem : **what if the information changes ?** What if we have thousands of documents that update every day ?\n",
    "\n",
    "Fine-tuning every time is expensive and slow. We need a smarter approach : **RAG** (Retrieval Augmented Generation).  \n",
    "\n",
    "Think of it like this :\n",
    "- **Fine-tuning** = Teaching a student new facts by heart (slow, expensive)\n",
    "- **RAG** = Giving the student access to a library and teaching them how to search (fast, flexible)\n",
    "\n",
    "But before building RAG, we need to understand **embeddings** - the magic that makes search work !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-title",
   "metadata": {},
   "source": [
    "# **I/ Understanding Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-intro",
   "metadata": {},
   "source": [
    "### **What is an Embedding ?**\n",
    "\n",
    "An embedding is a way to represent text (or images, audio...) as a **list of numbers** (a vector).  \n",
    "\n",
    "Imagine you want to organize books in a library. Instead of organizing them alphabetically, you organize them by **meaning** :\n",
    "- Books about cooking are close together\n",
    "- Books about space are close together\n",
    "- A book about \"cooking in space\" would be somewhere in between\n",
    "\n",
    "Embeddings do exactly this : texts with similar meanings have similar numbers (vectors that are \"close\" in space).\n",
    "\n",
    "**Example :**\n",
    "- \"I love pizza\" → [0.2, 0.8, 0.1, ...]\n",
    "- \"Pizza is my favorite food\" → [0.21, 0.79, 0.12, ...] (very similar)\n",
    "- \"The weather is nice\" → [0.9, 0.1, 0.7, ...] (very different)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-packages",
   "metadata": {},
   "source": [
    "### ***1/ Setup: Install the necessary packages***"
   ]
  },
  {
   "cell_type": "code",
   "id": "install-cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:11:00.159181395Z",
     "start_time": "2026-02-10T16:10:59.401751072Z"
    }
   },
   "source": [
    "%pip install sentence-transformers chromadb numpy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (5.2.2)\r\n",
      "Requirement already satisfied: chromadb in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (1.5.0)\r\n",
      "Requirement already satisfied: numpy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (5.1.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.4.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.10.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.8.0)\r\n",
      "Requirement already satisfied: scipy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.17.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\r\n",
      "Requirement already satisfied: tqdm in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.3)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.4.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (2.12.5)\r\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.4.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\r\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.24.1)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.22.2)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.51.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (1.78.0)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.0.0)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.21.1)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (35.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (9.1.4)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (6.0.3)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (3.11.7)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (14.3.2)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from chromadb) (4.26.0)\r\n",
      "Requirement already satisfied: packaging>=24.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (26.0)\r\n",
      "Requirement already satisfied: pyproject_hooks in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: anyio in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2026.1.4)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.11)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\r\n",
      "Requirement already satisfied: filelock in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\r\n",
      "Requirement already satisfied: shellingham in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\r\n",
      "Requirement already satisfied: typer-slim in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: requests in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\r\n",
      "Requirement already satisfied: requests-oauthlib in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.6.3)\r\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\r\n",
      "Requirement already satisfied: flatbuffers in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\r\n",
      "Requirement already satisfied: protobuf in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\r\n",
      "Requirement already satisfied: sympy in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\r\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.4.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\r\n",
      "Requirement already satisfied: setuptools in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (82.0.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\r\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.9.4)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\r\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\r\n",
      "Requirement already satisfied: triton==3.6.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers) (1.3.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\r\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\r\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\r\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "create-embedding-title",
   "metadata": {},
   "source": [
    "### ***2/ Create your first embedding***\n",
    "\n",
    "We will use a pre-trained model from HuggingFace to create embeddings.  \n",
    "The model `all-MiniLM-L6-v2` is small, fast, and works great for most use cases.\n",
    "\n",
    "**Documentation :** https://www.sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "id": "first-embedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:11:02.143316402Z",
     "start_time": "2026-02-10T16:11:00.160697048Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# TODO: Load the embedding model 'all-MiniLM-L6-v2'\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "text = \"I love artificial intelligence\"\n",
    "\n",
    "# TODO: Create the embedding\n",
    "embedding = embedding_model.encode(text)\n",
    "\n",
    "print(f\"Embedding created.\")\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1747.31it/s, Materializing param=pooler.dense.weight]                        \n",
      "\u001B[1mMPNetModel LOAD REPORT\u001B[0m from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding created.\n",
      "Embedding dimension: 768\n",
      "First 10 values: [-0.04087291  0.07031951 -0.04249007 -0.01306419 -0.02507559  0.04857958\n",
      " -0.03809898 -0.00214754  0.00031533  0.02278556]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "similarity-title",
   "metadata": {},
   "source": [
    "### ***3/ Measure similarity between texts***\n",
    "\n",
    "Now comes the magic. We can measure how similar two texts are by comparing their embeddings.  \n",
    "We use **cosine similarity** : a value between -1 and 1, where 1 means \"identical meaning\".\n",
    "\n",
    "**Documentation :** https://www.sbert.net/docs/package_reference/util.html\n",
    "\n",
    "**Your task :** Complete the code to calculate similarity between sentences."
   ]
  },
  {
   "cell_type": "code",
   "id": "similarity-calc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:20:36.476901697Z",
     "start_time": "2026-02-10T16:20:36.413388309Z"
    }
   },
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "sentences = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is my favorite programming language\",\n",
    "    \"The weather is beautiful today\",\n",
    "    \"I enjoy coding and building software\"\n",
    "]\n",
    "\n",
    "# TODO: Create embeddings for all sentences\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "print(\"Similarity with 'I love programming in Python':\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # TODO: Calculate cosine similarity between first embedding and current one\n",
    "    similarity = util.cos_sim(embeddings[0], embeddings[i]).item()\n",
    "    print(f\"  \\\"{sentence}\\\"\")\n",
    "    print(f\"  → Similarity: {similarity:.4f}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with 'I love programming in Python':\n",
      "\n",
      "  \"I love programming in Python\"\n",
      "  → Similarity: 1.0000\n",
      "\n",
      "  \"Python is my favorite programming language\"\n",
      "  → Similarity: 0.8861\n",
      "\n",
      "  \"The weather is beautiful today\"\n",
      "  → Similarity: 0.0930\n",
      "\n",
      "  \"I enjoy coding and building software\"\n",
      "  → Similarity: 0.6886\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "question-similarity",
   "metadata": {},
   "source": [
    "**Question :** Which sentences have the highest similarity ? Does it make sense to you ?  \n",
    "Take a moment to analyze the results before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-title",
   "metadata": {},
   "source": [
    "### ***4/ Visualize embeddings (bonus)***\n",
    "\n",
    "Embeddings have 384 dimensions - impossible to visualize directly.  \n",
    "We can use **dimensionality reduction** to project them into 2D and see how texts are organized.\n",
    "\n",
    "**Documentation :** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "This is optional but helps understand how embeddings work."
   ]
  },
  {
   "cell_type": "code",
   "id": "visualize-embeddings",
   "metadata": {},
   "source": [
    "%pip install matplotlib scikit-learn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "texts = [\n",
    "    # Tech topic\n",
    "    \"I love programming in Python\",\n",
    "    \"JavaScript is great for web development\",\n",
    "    \"Machine learning is fascinating\",\n",
    "    # Food topic  \n",
    "    \"Pizza is my favorite food\",\n",
    "    \"I love cooking Italian pasta\",\n",
    "    \"Sushi is delicious\",\n",
    "    # Nature topic\n",
    "    \"The mountains are beautiful\",\n",
    "    \"I love hiking in the forest\",\n",
    "    \"The ocean is peaceful\"\n",
    "]\n",
    "\n",
    "# TODO: Create embeddings for all texts\n",
    "text_embeddings = ...\n",
    "\n",
    "# TODO: Reduce to 2D using PCA\n",
    "pca = ...\n",
    "embeddings_2d = ...\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['blue', 'blue', 'blue', 'red', 'red', 'red', 'green', 'green', 'green']\n",
    "\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    plt.scatter(x, y, c=colors[i], s=100)\n",
    "    plt.annotate(texts[i][:30] + \"...\", (x, y), fontsize=8)\n",
    "\n",
    "plt.title(\"Embeddings visualized in 2D (Blue=Tech, Red=Food, Green=Nature)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice how similar topics cluster together.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "part2-title",
   "metadata": {},
   "source": [
    "# **II/ Building a Vector Database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vectordb-intro",
   "metadata": {},
   "source": [
    "Now that we understand embeddings, we need a place to **store** them efficiently.  \n",
    "\n",
    "A **vector database** is like a regular database, but optimized for :\n",
    "- Storing embeddings (lists of numbers)\n",
    "- Finding similar vectors very fast (even with millions of entries)\n",
    "\n",
    "We will use **ChromaDB**, which is simple and works great for learning.\n",
    "\n",
    "**Other popular options :** Pinecone, Weaviate, Qdrant, FAISS, Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-db-title",
   "metadata": {},
   "source": [
    "### ***1/ Create a ChromaDB collection***\n",
    "\n",
    "A \"collection\" in ChromaDB is like a table in a regular database.  \n",
    "It stores your documents and their embeddings.\n",
    "\n",
    "**Documentation :** https://docs.trychroma.com/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "id": "create-chromadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:28:33.679396522Z",
     "start_time": "2026-02-10T16:28:33.355455520Z"
    }
   },
   "source": [
    "import chromadb\n",
    "\n",
    "# TODO: Create a ChromaDB client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# TODO: Create a collection named \"my_knowledge_base\"\n",
    "collection = chroma_client.create_collection(name=\"my_knowledge_base\")\n",
    "\n",
    "print(f\"Collection '{collection.name}' created.\")\n",
    "print(f\"Currently contains {collection.count()} documents\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_knowledge_base' created.\n",
      "Currently contains 0 documents\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "add-docs-title",
   "metadata": {},
   "source": [
    "### ***2/ Add documents to the database***\n",
    "\n",
    "Let's add some documents about a fictional company.  \n",
    "Later, we will ask questions and retrieve relevant information.\n",
    "\n",
    "**Your task :** Add documents to the collection using the `add()` method.\n",
    "\n",
    "**Hint :** ChromaDB requires each document to have a **unique string ID**. You can generate them from the index, for example : `[\"doc_0\", \"doc_1\", \"doc_2\", ...]`.  \n",
    "Use a list comprehension like `[f\"doc_{i}\" for i in range(len(documents))]` to create them."
   ]
  },
  {
   "cell_type": "code",
   "id": "add-documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:34:46.783224662Z",
     "start_time": "2026-02-10T16:34:46.492897689Z"
    }
   },
   "source": [
    "documents = [\n",
    "    \"TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\",\n",
    "    \"TechCorp specializes in artificial intelligence solutions for healthcare.\",\n",
    "    \"The company has 150 employees and offices in San Francisco and London.\",\n",
    "    \"TechCorp's main product is MedAI, a diagnostic assistant for doctors.\",\n",
    "    \"In 2023, TechCorp raised $50 million in Series B funding from Sequoia Capital.\",\n",
    "    \"The CEO of TechCorp is Alice Johnson, who previously worked at Google.\",\n",
    "    \"TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\",\n",
    "    \"The company plans to expand to Asia in 2024, starting with Japan and Singapore.\",\n",
    "    \"MedAI can analyze X-rays, MRIs, and CT scans with 95% accuracy.\",\n",
    "    \"TechCorp won the Best AI Startup award at TechCrunch Disrupt 2023.\"\n",
    "]\n",
    "\n",
    "# TODO: Add documents to the collection with unique IDs\n",
    "collection.add(\n",
    "    ids=[f'doc_{index}' for index, doc in enumerate(documents)],\n",
    "    documents=documents,\n",
    ")\n",
    "\n",
    "print(f\"Added {collection.count()} documents to the collection.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 11 documents to the collection.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "query-title",
   "metadata": {},
   "source": [
    "### ***3/ Search for relevant documents***\n",
    "\n",
    "Now the magic happens. We can search for documents by **meaning**, not just keywords.  \n",
    "The database will find documents that are semantically similar to our query.\n",
    "\n",
    "**Your task :** Use the `query()` method to search for relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "query-documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:37:15.561234209Z",
     "start_time": "2026-02-10T16:37:15.397069734Z"
    }
   },
   "source": [
    "query = \"Who founded the company and when ?\"\n",
    "\n",
    "# TODO: Query the collection and get 3 results\n",
    "results = collection.query(\n",
    "    query_texts=query,\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(\"Most relevant documents:\")\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"  {i+1}. {doc}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"Who founded the company and when ?\"\n",
      "\n",
      "Most relevant documents:\n",
      "  1. TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n",
      "  2. The CEO of TechCorp is Alice Johnson, who previously worked at Google.\n",
      "  3. The company has 150 employees and offices in San Francisco and London.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "experiment-title",
   "metadata": {},
   "source": [
    "### ***4/ Experiment with different queries***\n",
    "\n",
    "Try different questions and see how the system finds relevant documents.  \n",
    "Notice how it understands meaning, not just exact word matches."
   ]
  },
  {
   "cell_type": "code",
   "id": "experiment-queries",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:42:48.516454282Z",
     "start_time": "2026-02-10T16:42:47.882376622Z"
    }
   },
   "source": [
    "test_queries = [\n",
    "    \"What does the company sell ?\",\n",
    "    \"How much money did they raise ?\",\n",
    "    \"Where are the offices located ?\",\n",
    "    \"Tell me about the medical AI product\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    # TODO: Query the collection with 2 results\n",
    "    results = collection.query(\n",
    "    query_texts=query,\n",
    "    n_results=2,\n",
    ")\n",
    "    \n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(\"Results:\")\n",
    "    for doc in results['documents'][0]:\n",
    "        print(f\"   → {doc}\")\n",
    "    print(\"-\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: \"What does the company sell ?\"\n",
      "Results:\n",
      "   → The company has 150 employees and offices in San Francisco and London.\n",
      "   → The CEO of TechCorp is Alice Johnson, who previously worked at Google.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"How much money did they raise ?\"\n",
      "Results:\n",
      "   → In 2023, TechCorp raised $50 million in Series B funding from Sequoia Capital.\n",
      "   → TechCorp's revenue in 2023 was $25 million, a 150% increase from 2022.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"Where are the offices located ?\"\n",
      "Results:\n",
      "   → The company has 150 employees and offices in San Francisco and London.\n",
      "   → TechCorp was founded in 2020 by Alice Johnson and Bob Smith in San Francisco.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Query: \"Tell me about the medical AI product\"\n",
      "Results:\n",
      "   → TechCorp specializes in artificial intelligence solutions for healthcare.\n",
      "   → TechCorp's main product is MedAI, a diagnostic assistant for doctors.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "part3-title",
   "metadata": {},
   "source": [
    "# **III/ Building a RAG System**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rag-intro",
   "metadata": {},
   "source": [
    "Now we combine everything into a complete **RAG** (Retrieval Augmented Generation) system.\n",
    "\n",
    "**How RAG works :**\n",
    "1. User asks a question\n",
    "2. We **search** our vector database for relevant documents (Retrieval)\n",
    "3. We give those documents + the question to an **LLM** (Augmented)\n",
    "4. The LLM generates an answer based on the context (Generation)\n",
    "\n",
    "This is powerful because :\n",
    "- The LLM has access to **your specific data**\n",
    "- Answers are **grounded** in real documents (less hallucination)\n",
    "- You can **update** the knowledge base without retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-llm-title",
   "metadata": {},
   "source": [
    "ic key is:\n",
    "test_queries### ***1/ Setup the LLM***\n",
    "\n",
    "We will use the **Ollama** API to run a local LLM.\n",
    "\n",
    "**First, install Ollama and download the model :**\n",
    "\n",
    "1. Install Ollama from [ollama.com](https://ollama.com/)\n",
    "2. Open a terminal and run :\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "```\n",
    "3. Make sure Ollama is running :\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "**Documentation :** https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion"
   ]
  },
  {
   "cell_type": "code",
   "id": "setup-llm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T16:54:43.688700498Z",
     "start_time": "2026-02-10T16:54:43.060958363Z"
    }
   },
   "source": [
    "%pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "LLM_URL = \"http://localhost:11434/api/generate\"\n",
    "LLM_MODEL = \"llama3.2:3b\"\n",
    "\n",
    "print(f\"Using Ollama with model: {LLM_MODEL}\")\n",
    "print(\"Make sure Ollama is running: 'ollama serve'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (2.32.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maxens/tek2/piscinePoc/day2/.venv/lib/python3.12/site-packages (from requests) (2026.1.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m26.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Using Ollama with model: llama3.2:3b\n",
      "Make sure Ollama is running: 'ollama serve'\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "rag-function-title",
   "metadata": {},
   "source": [
    "### ***2/ Build the RAG pipeline***\n",
    "\n",
    "Let's create a function that :\n",
    "1. Takes a user question\n",
    "2. Retrieves relevant documents from ChromaDB\n",
    "3. Creates a prompt with the context\n",
    "4. Sends it to the LLM and returns the answer\n",
    "\n",
    "**Your task :** Complete the RAG function below.\n",
    "\n",
    "**Hint :** To call Ollama, use the `requests` library :\n",
    "```python\n",
    "response = requests.post(LLM_URL, json={\n",
    "    \"model\": LLM_MODEL,\n",
    "    \"prompt\": your_prompt,\n",
    "    \"stream\": False\n",
    "})\n",
    "```\n",
    "The answer is in `response.json()[\"response\"]`."
   ]
  },
  {
   "cell_type": "code",
   "id": "rag-function",
   "metadata": {},
   "source": [
    "def ask_with_rag(question: str, n_results: int = 3) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    RAG pipeline: Retrieve relevant docs and generate an answer.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question\n",
    "        n_results: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (answer, source documents)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Retrieve relevant documents from the collection\n",
    "    results = collection.query(\n",
    "        query_texts=question,\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    \n",
    "    # TODO: Build the context string from retrieved documents\n",
    "    context = ...\n",
    "    \n",
    "    # TODO: Create a prompt that includes the context and question\n",
    "    prompt = ...\n",
    "    \n",
    "    # TODO: Call Ollama API and extract the response\n",
    "    response = ...\n",
    "    answer = ...\n",
    "    \n",
    "    return answer, results['documents'][0]\n",
    "\n",
    "print(\"RAG function created.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "test-rag-title",
   "metadata": {},
   "source": [
    "### ***3/ Test your RAG system***\n",
    "\n",
    "Now let's test our RAG system with various questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "test-rag",
   "metadata": {},
   "source": [
    "test_questions = [\n",
    "    \"Who is the CEO of TechCorp ?\",\n",
    "    \"What is MedAI and what can it do ?\",\n",
    "    \"How much funding did the company raise ?\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    try:\n",
    "        answer, sources = ask_with_rag(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"\\nSources used:\")\n",
    "        for source in sources:\n",
    "            print(f\"   - {source}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure Ollama is running or your API key is set.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "compare-title",
   "metadata": {},
   "source": [
    "### ***4/ Compare: With RAG vs Without RAG***\n",
    "\n",
    "Let's see the difference between asking the LLM directly vs using RAG.  \n",
    "This shows why RAG is so powerful for domain-specific questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "compare-rag",
   "metadata": {},
   "source": [
    "def ask_without_rag(question: str) -> str:\n",
    "    \"\"\"Ask the LLM directly without any context.\"\"\"\n",
    "    # TODO: Create a simple prompt and call Ollama\n",
    "    ...\n",
    "\n",
    "question = \"Who is the CEO of TechCorp and what is their background ?\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"\\nWITHOUT RAG (LLM doesn't know about TechCorp):\")\n",
    "    print(ask_without_rag(question))\n",
    "    \n",
    "    print(\"\\nWITH RAG (LLM has access to our documents):\")\n",
    "    answer, _ = ask_with_rag(question)\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "part4-title",
   "metadata": {},
   "source": [
    "# **IV/ RAG on Real Documents : Chunking & Multi-File Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunking-intro",
   "metadata": {},
   "source": [
    "### ***1/ Understanding chunking***\n",
    "\n",
    "In Parts II and III, we worked with short, single-sentence documents. That made things easy.  \n",
    "But in real applications, your knowledge base is made of **long documents** : PDFs, reports, articles, internal docs...\n",
    "\n",
    "You can't just embed an entire 10-page document as a single vector. Why ?\n",
    "- Embeddings work best on **short texts** (a few sentences). A single embedding for a whole document would lose the details.\n",
    "- When you retrieve a long document, most of it is **irrelevant** to the question. You'd waste the LLM's context window.\n",
    "- LLMs have **context limits** - you can't feed them an entire book.\n",
    "\n",
    "The solution is **chunking** : splitting long documents into smaller, meaningful pieces.\n",
    "\n",
    "**How chunking works :**\n",
    "- We define a **maximum chunk size** (e.g. 500 characters).\n",
    "- We walk through the text and cut at approximately every 500 characters.\n",
    "- But we don't cut in the middle of a sentence ! We look for the **last sentence boundary** (period, exclamation mark...) before the limit, so each chunk contains **complete sentences**.\n",
    "- We also add an **overlap** between chunks (e.g. 100 characters). This means the end of one chunk is repeated at the start of the next one. This prevents losing context at the boundaries - if an important fact spans two chunks, the overlap ensures it appears fully in at least one of them.\n",
    "\n",
    "**Example with chunk_size=500, overlap=100 :**\n",
    "```\n",
    "Document: \"Sentence A. Sentence B. Sentence C. Sentence D. Sentence E. ...\"\n",
    "\n",
    "Chunk 1: \"Sentence A. Sentence B. Sentence C.\"        (480 chars, cut at last period before 500)\n",
    "Chunk 2: \"Sentence C. Sentence D. Sentence E.\"          (starts 100 chars before the end of chunk 1)\n",
    "```\n",
    "\n",
    "In the `documents/` folder, you will find **5 text files** about TechCorp.  \n",
    "Your task is to implement the chunking function, load the files, chunk them, and build a complete RAG system over real documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "chunking-function",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks, cutting at sentence boundaries.\n",
    "    \n",
    "    Args:\n",
    "        text: The full text to chunk\n",
    "        chunk_size: Maximum size of each chunk (in characters)\n",
    "        overlap: Number of characters to overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        # TODO: Calculate the end position\n",
    "        end = ...\n",
    "        \n",
    "        # TODO: Try to end at a sentence boundary (find last period before end)\n",
    "        # Hint: use text.rfind(\".\", start, end) to find the last period in the range\n",
    "        if end < len(text):\n",
    "            ...\n",
    "        \n",
    "        # TODO: Extract the chunk (strip whitespace) and append it to the list\n",
    "        # TODO: Update start position (move forward by chunk length minus overlap)\n",
    "        ...\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --- Load all .txt files from the documents/ folder ---\n",
    "documents_dir = \"documents\"\n",
    "all_chunks = []\n",
    "chunk_sources = []\n",
    "\n",
    "for filename in sorted(os.listdir(documents_dir)):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "    \n",
    "    filepath = os.path.join(documents_dir, filename)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # TODO: Chunk the file content\n",
    "    file_chunks = ...\n",
    "    \n",
    "    for chunk in file_chunks:\n",
    "        all_chunks.append(chunk)\n",
    "        chunk_sources.append(filename)\n",
    "    \n",
    "    print(f\"Loaded '{filename}' -> {len(file_chunks)} chunks\")\n",
    "\n",
    "print(f\"\\nTotal: {len(all_chunks)} chunks from {len(set(chunk_sources))} files\")\n",
    "print(f\"\\nExample chunk (chunk #1):\")\n",
    "print(f\"  Source: {chunk_sources[0]}\")\n",
    "print(f\"  Length: {len(all_chunks[0])} chars\")\n",
    "print(f\"  Content: \\\"{all_chunks[0][:150]}...\\\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "hu04m2nke1s",
   "metadata": {},
   "source": [
    "### ***2/ Store chunks in a vector database***\n",
    "\n",
    "Now that we have chunks from multiple files, let's store them in a **new ChromaDB collection** and build a full RAG system over real documents.\n",
    "\n",
    "**Your task :** Add all chunks to a new collection, keeping track of which file each chunk came from (using **metadata**)."
   ]
  },
  {
   "cell_type": "code",
   "id": "sje1b7j0hds",
   "metadata": {},
   "source": [
    "# TODO: Create a new ChromaDB collection named \"techcorp_docs\"\n",
    "docs_collection = ...\n",
    "\n",
    "# TODO: Add all chunks to the collection\n",
    "# Each chunk needs: a unique ID, the chunk text as document, and metadata with the source filename\n",
    "# Hint: metadata is a list of dicts, e.g. [{\"source\": \"file1.txt\"}, {\"source\": \"file2.txt\"}, ...]\n",
    "...\n",
    "\n",
    "print(f\"Stored {docs_collection.count()} chunks in the 'techcorp_docs' collection.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0nbnuf5f9kg",
   "metadata": {},
   "source": [
    "### ***3/ RAG over real documents***\n",
    "\n",
    "Let's test our complete pipeline : **chunked documents + vector DB + LLM**.  \n",
    "The questions below require information spread across different files. Only a RAG system with proper chunking can answer them accurately."
   ]
  },
  {
   "cell_type": "code",
   "id": "4wy06z9srmu",
   "metadata": {},
   "source": [
    "def ask_docs(question: str, n_results: int = 5) -> tuple[str, list]:\n",
    "    \"\"\"RAG pipeline over the chunked documents collection.\"\"\"\n",
    "    \n",
    "    # TODO: Query the docs_collection for relevant chunks\n",
    "    results = ...\n",
    "    \n",
    "    # TODO: Build context from retrieved chunks\n",
    "    context = ...\n",
    "    \n",
    "    # TODO: Create a prompt and call Ollama (same pattern as ask_with_rag)\n",
    "    prompt = ...\n",
    "    \n",
    "    response = requests.post(LLM_URL, json={\n",
    "        \"model\": LLM_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    answer = response.json()[\"response\"]\n",
    "    \n",
    "    return answer, results['documents'][0], results['metadatas'][0]\n",
    "\n",
    "\n",
    "test_questions = [\n",
    "    \"What is TechCorp's revenue growth from 2022 to 2023 ?\",\n",
    "    \"Which hospitals are partners of TechCorp ?\",\n",
    "    \"What is PathAI and when will it launch ?\",\n",
    "    \"How does MedAI integrate into hospital workflows ?\",\n",
    "    \"What is TechCorp's expansion plan for Asia ?\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    try:\n",
    "        answer, sources, metadatas = ask_docs(question)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"\\nSources:\")\n",
    "        for source, meta in zip(sources, metadatas):\n",
    "            print(f\"   [{meta['source']}] {source[:80]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-title",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-content",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations !** You have completed this afternoon's session on RAG.\n",
    "\n",
    "**What you learned today :**\n",
    "\n",
    "- **Embeddings** : Transform text into vectors that capture meaning  \n",
    "- **Vector Databases** : Store and search embeddings efficiently (ChromaDB)  \n",
    "- **RAG Pipeline** : Retrieve relevant documents + Generate answers with LLM  \n",
    "- **Chunking** : Split large documents for better retrieval  \n",
    "\n",
    "**Key takeaways :**\n",
    "- RAG lets you give LLMs access to **your specific data** without retraining\n",
    "- Embeddings enable **semantic search** (by meaning, not just keywords)\n",
    "\n",
    "**What's next ? Ideas to explore :**\n",
    "- Check out `bonus.ipynb` for an introduction to **GraphRAG**\n",
    "- Build a RAG system with your own documents (PDFs, web pages)\n",
    "- Try different embedding models (Cohere, local models)\n",
    "- Add metadata filtering to your searches\n",
    "- Experiment with reranking strategies\n",
    "\n",
    "---\n",
    "\n",
    "**Combining with this morning :**  \n",
    "This morning you learned **fine-tuning** (adapting model weights).  \n",
    "This afternoon you learned **RAG** (giving the model external knowledge).  \n",
    "\n",
    "In practice, you often use **both** :\n",
    "- Fine-tune for style/format/domain language\n",
    "- RAG for factual, up-to-date information\n",
    "\n",
    "**Great work today !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
